# 五大组件

## Spring Cloud 5大组件有哪些？

早期我们一般认为的Spring Cloud五大组件是 

- Eureka : 注册中心,用来管理多个微服务的服务信息例如,ip,端口,服务名称等
- Ribbon : 负载均衡,如果微服务有多个集群,就需要进行负载均衡
- Feign : 远程调用,用来给各个微服务之间进行远程调用
- Hystrix : 服务熔断
- Zuul/Gateway : 网关,对外暴露接口也就是服务的入口

随着SpringCloudAlibba在国内兴起 , 我们项目中使用了一些阿里巴巴的组件 

- 注册中心/配置中心 Nacos
- 负载均衡 Ribbon
- 服务调用 Feign
- 服务保护 sentinel
- 服务网关 Gateway

## 服务注册和发现是什么意思？Spring Cloud 如何实现服务注册发现？

我理解的是主要三块大功能，分别是服务注册 、服务发现、服务状态监控

我们当时项目采用的eureka作为注册中心，这个也是spring cloud体系中的一个核心组件

**服务注册**：服务提供者需要把自己的信息注册到eureka，由eureka来保存这些信息，比如服务名称、ip、端口等等

**服务发现**：消费者向eureka拉取服务列表信息，如果服务提供者有集群，则消费者会利用负载均衡算法，选择一个发起调用

**服务监控**：服务提供者会每隔30秒向eureka发送心跳，报告健康状态，如果eureka服务90秒没接收到心跳，从eureka中剔除

## 我看你之前也用过nacos、你能说下nacos与eureka的区别？

选择nacos还要一个重要原因就是它支持配置中心，不过nacos作为注册中心，也比eureka要方便好用一些，主要相同不同点在于几点：

- 共同点

Nacos与eureka都支持服务注册和服务拉取，都支持服务提供者心跳方式做健康检测

- **Nacos与Eureka的区别**

①Nacos支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式

②临时实例心跳不正常会被剔除，非临时实例则不会被剔除

③Nacos支持服务列表变更的消息推送模式，服务列表更新更及时

④Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式；Eureka采用AP方式

# 负载均衡

## 你们项目负载均衡如何实现的 ? 

在服务调用过程中的负载均衡一般使用SpringCloud的Ribbon 组件实现 , Feign的底层已经自动集成了Ribbon , 使用起来非常简单

当发起远程调用时，ribbon先从注册中心拉取服务地址列表，然后按照一定的路由策略选择一个发起远程调用，一般的调用策略是轮询

## Ribbon负载均衡策略有哪些 ? 

- RoundRobinRule：简单轮询服务列表来选择服务器
- WeightedResponseTimeRule：按照权重来选择服务器，响应时间越长，权重越小
- RandomRule：随机选择一个可用的服务器
- ZoneAvoidanceRule：区域敏感策略，以区域可用的服务器为基础进行服务器的选择。使用Zone对服务器进行分类，这个Zone可以理解为一个机房、一个机架等。而后再对Zone内的多个服务做轮询(默认)

## 负载均衡有哪些算法？ *

- 简单轮询：将请求按顺序分发给后端服务器上，不关心服务器当前的状态，比如后端服务器的性能、当前的负载。
- 加权轮询：根据服务器自身的性能给服务器设置不同的权重，将请求按顺序和权重分发给后端服务器，可以让性能高的机器处理更多的请求
- 简单随机：将请求随机分发给后端服务器上，请求越多，各个服务器接收到的请求越平均
- 加权随机：根据服务器自身的性能给服务器设置不同的权重，将请求按各个服务器的权重随机分发给后端服务器
- 一致性哈希：根据请求的**客户端 ip、或请求参数通过哈希算法得到一个数值**，利用该数值取模映射出对应的后端服务器，这样能保证同一个客户端或相同参数的请求每次都使用同一台服务器
- 最小活跃数：统计每台服务器上当前正在处理的请求数，也就是请求活跃数，将请求分发给活跃数最少的后台服务器

## 如何实现一直均衡给一个用户？

可以通过「一致性哈希算法」来实现，根据请求的客户端 ip、或请求参数通过哈希算法得到一个数值，利用该数值取模映射出对应的后端服务器，这样能保证同一个客户端或相同参数的请求每次都使用同一台服务器。

## 如果想自定义负载均衡策略如何实现 ? 

提供了两种方式：

1，创建类实现IRule接口，可以指定负载均衡策略，这个是全局的，对所有的远程调用都起作用

2，在客户端的配置文件中，可以配置某一个服务调用的负载均衡策略，只是对配置的这个服务生效远程调用

# xxl-job

## xxl-job能用来做什么*

- 解决集群任务的重复执行问题

- 定时任务失败了，重试和统计

- 任务量大，分片执行

> 1,3可以扯到神灵物流项目

## xxl-job路由策略有哪些？

xxl-job提供了很多的路由策略，我们平时用的较多就是：轮询、==故障转移==、分片广播…

## xxl-job任务执行失败怎么解决？

第一：路由策略选择故障转移，优先使用健康的实例来执行任务

第二，如果还有失败的，我们在创建任务时，可以设置重试次数

第三，如果还有失败的，就可以查看日志或者配置邮件告警来通知相关负责人解决

## 如果有大数据量的任务同时都需要执行，怎么解决？

执行器集群部署时，任务路由策略选择分片广播情况下，一次任务调度将会广播触发对应集群中所有执行器执行一次任务

![image-20241022150340540](https://pic-1329573580.cos.ap-nanjing.myqcloud.com/202410221503630.png)

> 这里可以扯到神灵物流

# 分布式的理论

## 什么是CAP理论？*

CAP主要是在分布式项目下的一个理论。包含了三项，一致性、可用性、分区容错性

- **一致性**是指更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致(强一致性)，不能存在中间状态。

- **可用性**是指系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。

- **分区容错性**是指分布式系统在遇到任何网络分区故障时，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。

## 什么是BASE理论？*

BASE是CAP理论中AP方案的延伸，核心思想是即使无法做到强一致性，但应用可以采用适合的方式达到最终一致性。它的思想包含三方面：

1、**基本可用**：基本可用是指分布式系统在出现不可预知的故障的时候，允许损失部分可用性，但不等于系统不可用。

2、**软状态**：即是指允许系统中的数据存在中间状态，也就是允许短时间内不同步

3、**最终一致性**：强调系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。其本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。

## 什么是数据一致性？ *

**数据一致性分为强一致性、弱一致性、最终一致性**。

- 如果的确能像上面描述的那样时刻保证客户端看到的数据都是一致的，那么称之为强一致性。
- 如果允许存在中间状态，只要求经过一段时间后，数据最终是一致的，则称之为最终一致性。
- 此外，如果允许存在部分数据不一致，那么就称之为弱一致性。

## 为什么分布式系统中无法同时保证一致性和可用性？ *

首先一个前提，对于分布式系统而言，分区容错性是一个最基本的要求，因此基本上我们在设计分布式系统的时候只能从一致性（C）和可用性（A）之间进行取舍。

如果保证了一致性（C）：对于节点N1和N2，当往N1里写数据时，N2上的操作必须被暂停，只有当N1同步数据到N2时才能对N2进行读写请求，在N2被暂停操作期间客户端提交的请求会收到失败或超时。显然，这与可用性是相悖的。

如果保证了可用性（A）：那就不能暂停N2的读写操作，但同时N1在写数据的话，这就违背了一致性的要求。

# 分布式事务 *

## 分布式事务分类

### 刚性事务(cp,cap)

通常无业务改造，**强一致性**，原生支持回滚/隔离性，**低并发，适合短事务,适合银行业务**。

原则：刚性事务满足足CAP的CP理论

> 刚性事务指的是，要使分布式事务，达到像本地式事务一样，具备数据强一致性，从CAP来看，就是说，要达到CP状态。

刚性事务：XA 协议（**2PC**、JTA、JTS）、3PC，但由于**同步阻塞，处理效率低，不适合大型网站分布式场景。**

**优点**:强一致性

**缺点**:阻塞问题,依赖数据库问题

#### 2PC

2PC是强一致性问题的解决方案,分为俩阶段

2PC 二阶段提交主要将提交协议节点分为**协调者**、参与者

**2PC俩个阶段**

- 提交事务请求
  - 也就是询问各个参与者/数据库有没有准备好
- 根据结果决定提交事务或者中断事务
  - 所有参与者都需要向协调者回个ACK即YES/NO请求,只要有一个为NO则中断事务,通知所有参与者回滚

**缺陷**

同步阻塞问题

- 当回ACK的时候需要等待别的参与者,也就是需要等待执行时间最长的那个参与者执行完才能确定是提交还是中断事务

单点故障问题

- 协调者是单个的,如果挂了没有完善的容错机制

资源浪费问题

- 2PC的阶段需要先提交请求,再通过ACK确定是否可以提交事务,如果某个服务本来就不可用那么其他服务还要走这个流程,不能提前就知道可不可用,如果可以提前知道那么甚至都可以不用让别的服务去做操作

#### 3PC

3PC是2PC的升级,3PC主要就是**解决单点故障问题,以及资源浪费问题**

3PC三个阶段:

- **CanCommit**(多出来的)
  - 询问
  - 多出来的阶段,询问参与者是否可用,而不是像2PC一样直接让服务去执行然后通过ACK判断是否回滚,所以当询问时不可用就不用去让服务器执行避免这次执行的资源浪费
- PreCommit
  - 执行事务但不提交,这个阶段还是会全局阻塞
- DoCommit
  - 这个阶段如果参与者没有收到提交请求,会在等待超时后提交事务
  - 当进入第三阶段时，由于网络超时/网络分区等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。

> 但是同样的,在你开启事务阶段为了保证隔离性还是会进行阻塞,阻塞问题没有解决

### 柔性事务(base,ap)

柔性事务指的是，不要求强一致性，而是要求**最终一致性**，允许有中间状态，也就是Base理论，换句话说，就是AP状态,适合一些互联网业务。

> 与刚性事务相比，柔性事务的特点为：有业务改造，最终一致性，实现补偿接口，实现资源锁定接口，高并发，适合长事务。

柔性事务分为：

- 补偿型(TCC,saga)
- 通知型
  - 异步确保型
  - 最大努力通知型。


> 补偿型事务都是同步的，通知型事务都是异步的。

柔型事务：TCC/FMT、Saga、本地事务消息、消息事务（半消息）

#### 补偿型

##### TCC

**TCC 分布式事务模型包括三部分：**

![在这里插入图片描述](https://ucc.alicdn.com/r43put2rqnbp4/developer-article1629555/20241024/62c12088f57c489b9c1ef09f852423ff.png)

**Try 阶段**： 调用 Try 接口，尝试执行业务，完成所有业务检查，预留业务资源。

**Confirm 或 Cancel 阶段**： 两者是互斥的，只能进入其中一 个，并且都满足幂等性，允许失败重试。

**Confirm 操作**： 对业务系统做确认提交，确认执行业务操作，不做其他业务检查，只使用 Try 阶段预留的业务资源。
**Cancel 操作**： 在业务执行错误，需要回滚的状态下执行业务取消，释放预留资源。

> *Try 阶段失败可以 Cancel，如果 Confirm 和 Cancel 阶段失败了怎么办？*

TCC 中会添加事务日志，如果 Confirm 或者 Cancel 阶段出错，则会进行重试，所以这两个阶段需要支持幂等；如果重试失败，则需要人工介入进行恢复和处理等。

优点:

- 解决刚性事务阻塞问题
- 不需要依赖数据库

缺点:

- 代码侵入强,微服务的**每个事务都必须实现try、confirm、cancel等3个方法，开发成本高**

###### **TCCvs2PC**

- XA(2pc)是资源层面的分布式事务，**强一致性，在两阶段提交的整个过程中，一直会持有资源的锁,性能差。**基于数据库锁实现，需要数据库支持XA协议，由于在执行事务的全程都需要对相关数据加锁，一般高并发性能会比较差
- TCC是业务层面的分布式事务，**最终一致性，不会一直持有资源的锁，性能较好。**但是对微服务的侵入性强，微服务的**每个事务都必须实现try、confirm、cancel等3个方法，开发成本高**，今后维护改造的成本也高为了达到事务的一致性要求，try、confirm、cancel接口必须实现幂等性操作由于事务管理器要记录事务日志，必定会损耗一定的性能，并使得整个TCC事务时间拉长

##### saga 

**对业务侵入较小**，只需要提供一个逆向操作的Cancel即可,适用于长事务,业务流程多；

- 一阶段提交本地事务，无锁，高性能；
- 反向回滚,协调者询问是否需要回滚,需要就反SQL



#### 通知型

![image-20241021160127890](https://pic-1329573580.cos.ap-nanjing.myqcloud.com/202410211602753.png)

通知型事务的主流实现是通过MQ（消息队列）来通知其他事务参与者自己事务的执行状态，引入MQ组件，有效的将事务参与者进行解耦，各参与者都可以异步执行，所以通知型事务又被称为**异步事务**。

通知型事务主要适用于那些需要异步更新数据，并且对数据的实时性要求较低的场景，主要包含:

> **异步确保型事务**和**最大努力通知事务**两种。

- **异步确保型事务**：主要适用于内部系统的数据最终一致性保障，因为内部相对比较可控，如订单和购物车、收货与清算、支付与结算等等场景；
- **最大努力通知**：主要用于外部系统，因为外部的网络环境更加复杂和不可信，所以只能尽最大努力去通知实现数据最终一致性，比如充值平台与运营商、支付对接等等跨网络系统级别对接；

##### 事务消息 (异步确保型、半消息)

**半消息的作用**

半消息保证上游消息一定是能发送到MQ的,如果不是半消息先insert然后发送到MQ出问题了,insert的数据不会回滚,但是半消息可以

基于MQ的事务消息方案主要依靠MQ的**半消息机制**来实现投递消息和参与者自身本地事务的一致性保障。

有一些第三方的MQ是支持事务消息的，这些消息队列，支持半消息机制，比如RocketMQ，ActiveMQ。但是有一些常用的MQ也不支持事务消息，比如 RabbitMQ 和 Kafka 都不支持。

以阿里的 RocketMQ 中间件为例，其思路大致为：

1.producer(本例中指A系统)发送半消息到broker，这个半消息不是说消息内容不完整， 它包含完整的消息内容， 在producer端和普通消息的发送逻辑一致

2.broker存储半消息，半消息存储逻辑与普通消息一致，只是属性有所不同，topic是固定的RMQ_SYS_TRANS_HALF_TOPIC，queueId也是固定为0，这个tiopic中的消息对消费者是不可见的，所以里面的消息永远不会被消费。这就保证了在半消息提交成功之前，消费者是消费不到这个半消息的

3.broker端半消息存储成功并返回后，A系统执行本地事务，并根据本地事务的执行结果来决定半消息的提交状态为提交或者回滚

4.A系统发送结束半消息的请求，并带上提交状态(提交 or 回滚)

5.broker端收到请求后，首先从RMQ_SYS_TRANS_HALF_TOPIC的queue中查出该消息，设置为完成状态。如果消息状态为提交，则把半消息从RMQ_SYS_TRANS_HALF_TOPIC队列中复制到这个消息原始topic的queue中去(之后这条消息就能被正常消费了)；如果消息状态为回滚，则什么也不做。

6.producer发送的半消息结束请求是 oneway 的，也就是发送后就不管了，只靠这个是无法保证半消息一定被提交的，rocketMq提供了一个兜底方案，这个方案叫消息反查机制，Broker启动时，会启动一个TransactionalMessageCheckService 任务，该任务会定时从半消息队列中读出所有超时未完成的半消息，针对每条未完成的消息，Broker会给对应的Producer发送一个消息反查请求，根据反查结果来决定这个半消息是需要提交还是回滚，或者后面继续来反查

7.consumer(本例中指B系统)消费消息，执行本地数据变更(至于B是否能消费成功，消费失败是否重试，这属于正常消息消费需要考虑的问题)

![在这里插入图片描述](https://pic-1329573580.cos.ap-nanjing.myqcloud.com/202410221056876.png)

在rocketMq中，不论是producer收到broker存储半消息成功返回后执行本地事务，还是broker向producer反查消息状态，都是通过**回调机制**完成

##### 最大努力通知型

要实现最大努力通知，可以采用 MQ 的 ACK 机制。

最大努力通知事务在投递之前，跟**异步确保型流程**都差不多，关键在于投递后的处理。

- 业务主动方在完成业务处理后，向业务被动方(第三方系统)发送通知消息，**允许存在消息丢失**。
- 业务主动方提供递增多挡位时间间隔(5min、10min、30min、1h、24h)，用于失败重试调用业务被动方的接口；在通知N次之后就不再通知，**报警+记日志+人工介入**。
- **业务被动方提供幂等的服务接口，防止通知重复消费。**
- 业务主动方需要有定期校验机制，对业务数据进行兜底；防止业务被动方无法履行责任时进行业务回滚，确保数据最终一致性。

![img](https://pic-1329573580.cos.ap-nanjing.myqcloud.com/202410211906333.png)

1. 业务活动的主动方，在完成业务处理之后，向业务活动的被动方发送消息，允许消息丢失。
2. 主动方可以设置时间阶梯型通知规则，在通知失败后按规则重复通知，直到通知N次后不再通知。
3. 主动方提供校对查询接口给被动方按需校对查询，用于恢复丢失的业务消息。
4. 业务活动的被动方如果正常接收了数据，就正常返回响应，并结束事务。
5. 如果被动方没有正常接收，根据定时策略，向业务活动主动方查询，恢复丢失的业务消息。

**特点**

1. 用到的服务模式：可查询操作、幂等操作；
2. 被动方的处理结果不影响主动方的处理结果；
3. 适用于对业务最终一致性的时间敏感度低的系统；
4. 适合跨企业的系统间的操作，或者企业内部比较独立的系统间的操作，比如银行通知、商户通知等；

##### 最大努力通知vs异步确保型

事务在我认知中，其实是基于异步确保型事务发展而来适用于**外部对接**的一种业务实现。他们主要有的是业务差别，如下：

- 从参与者来说：最大努力通知事务适用于**跨平台、跨企业的系统间业务交互**；异步确保型事务更适用于同网络体系的**内部服务交付**。 
- 最大努力型不能保证操作的正确性和可靠性。在某些场景下，最大努力型是可以接受的，比如在数据采集、日志记录等场景中，只要尽可能地将数据保存下来即可。而异步确保型是**一定要你数据最终一致**
  - 就比如我我这个删除俩个文章的,我这边产品明确跟我说了删除微医文章就删除微信文章,这里是允许删除微医文章成功,微信那边失败的,因为微信那边的文章不是个人发的,而是以官方发的,到时候我们内部人员自己去微信公众号处理这种失败的情况,所以其实可以允许一边成功一边失败,只是说尽可能保证数据一致性

#### 补偿性vs通知型

补偿型事务都是**同步**的，通知型事务都是**异步**的。

## 总结

**2PC/3PC**：依赖于数据库，能够很好的提供强一致性和强事务性，但延迟比较高，比较适合传统的单体应用，在同一个方法中存在跨库操作的情况，不适合高并发和高性能要求的场景。
**TCC**：适用于执行时间确定且较短，实时性要求高，对数据一致性要求高，比如互联网金融企业最核心的三个服务：交易、支付、账务。
**本地消息表/MQ 事务**：适用于事务中参与方支持操作幂等，对一致性要求不高，业务上能容忍数据不一致到一个人工检查周期，事务涉及的参与方、参与环节较少，业务上有对账/校验系统兜底。
**Saga 事务**：由于 Saga 事务不能保证隔离性，需要在业务层控制并发，适合于业务场景事务并发操作同一资源较少的情况。Saga 由于缺少预提交动作，导致补偿动作的实现比较麻烦，例如业务是发送短信，补偿动作则得再发送一次短信说明撤销，用户体验比较差。所以，Saga 事务较适用于补偿动作容易处理的场景

## Seata

- XA模式,CP，需要互相等待各个分支事务提交，可以保证强一致性，性能差
- AT模式,AP，底层使用undo log 实现，性能好
- TCC模式，AP，性能较好，不过需要人工编码实现

# 分布式服务的接口幂等性如何设计？

## 什么情况会出现幂等问题

- 用户重复点击(网络波动)
- MQ消息重复
- 应用使用失败或超时重试机制

## 接口幂等性分析

![image-20241022143657733](https://pic-1329573580.cos.ap-nanjing.myqcloud.com/202410221436903.png)

![image-20241022143732043](https://pic-1329573580.cos.ap-nanjing.myqcloud.com/202410221437123.png)

> 修改的话下面这种增量修改就会有幂等问题

## 解决方案

- 数据库唯一索引 : 只能解决新增的幂等问题
- token+redis : 新增、修改都能解决
- 分布式锁 : 新增、修改都能解决

## redis+token *

![image-20241022145001977](https://pic-1329573580.cos.ap-nanjing.myqcloud.com/202410221450100.png)

这里能解决幂等问题主要是因为第三步如果处理了消息则删除token,这样下次访问redis的时候继续使用这个token已经被删掉了

性能好

> redis+token不止可以解决幂等问题,还能用来做登录场景

## 分布式锁

![image-20241022145327701](https://pic-1329573580.cos.ap-nanjing.myqcloud.com/202410221453790.png)

> 分布式锁的方案只能解决用户频繁点击造成的幂等问题,并且性能低

## 数据库唯一索引

数据库唯一索引保证你就算消费俩条消息比如说新增,这里也因为唯一的特性保证有一条sql成功

这里特指新增的情况,如果是增量修改数据库数据唯一的特性也就没用了

> 那么数据库是怎么解决并发问题的呢

insert操作数据库属于当前读,当前读会加锁,加锁就能解决并发问题

一般都是使用数据库做兜底策略,常见的幂等处理就是

1. 锁
2. 判断
3. 数据库唯一兜底

## 总结

- 幂等: 多次调用方法或者接口不会改变业务状态，可以保证重复调用的结果和单次调用的结果一致

- 如果是新增数据，可以使用数据库的唯一索引

- 如果是新增或修改数据
  - 分布式锁，性能较低
  - 使用token+redis来实现，性能较好

# 限流

## 常规项目架构

![image-20241022121643390](https://pic-1329573580.cos.ap-nanjing.myqcloud.com/202410221216472.png)

## 为什么要限流?

1. 并发量大,秒杀场景
2. 防止用户恶意刷接口

## 限流的实现方式

- nginx漏桶算法
- 网关:令牌桶算法
- 自定义拦截器

## Nginx限流

![image-20241022121911143](https://pic-1329573580.cos.ap-nanjing.myqcloud.com/202410221219236.png)

## 网关限流

![image-20241022122003196](`)

## 常见的限流算法

### 固定窗口

他有个固定窗口,这个固定窗口有一个请求阈值,当超过这个阈值就拒绝请求举个例子:

我窗口时间为5,总时间15,阈值3,我在15秒内划分了三个窗口,一开始0-5s的时候进来一个请求,计数器+1,当0-5s内计数器到3下一次在发请求就会拒绝,直到6~10s重新开始计数,以此类推

缺点:可能会出现临界问题也就是短时间内俩倍阈值的请求数,比如说我0-5 6-10 我在5秒和6秒的时候访问个三次请求也就是说宏观上来看2秒内访问了6次,其实不太好所以就有了滑动窗口

![img](https://cdn.nlark.com/yuque/0/2024/png/38443033/1718874755256-e049014a-7a4d-49fd-b6e8-e8cd26bc8c9b.png?x-oss-process=image%2Fformat%2Cwebp%2Fresize%2Cw_937%2Climit_0)

### 滑动窗口限流算法 

滑动窗口限流解决固定窗口临界值的问题。它将单位时间周期分为n个小周期，分别记录每个小周期内接口的访问次数，并且根据时间滑动删除过期的小周期。

一张图解释滑动窗口算法，如下：

![img](https://cdn.nlark.com/yuque/0/2024/png/38443033/1718875001368-47d61d5b-c7ba-4c5b-9ece-facfeee1b53f.png?x-oss-process=image%2Fformat%2Cwebp%2Fresize%2Cw_937%2Climit_0)

假设单位时间还是5s，滑动窗口算法把它划分为5个小周期，也就是滑动窗口（单位时间）被划分为5个小格子。每格表示1s。每过1s，时间窗口就会往右滑动一格。然后呢，每个小周期，都有自己独立的计数器，如果请求是3s到达的，0~5s对应的计数器就会加1。

我们来看下滑动窗口是如何解决临界问题的？

假设我们5s内的限流阀值还是3个请求，0~5s内（比如5s的时候）来了3个请求，落在5秒小窗口里。时间过了1.0s这个点之后，又来5个请求，落在6s格子里。如果是固定窗口算法，是不会被限流的，但是滑动窗口的话，每过一个小周期，它会右移一个小格。过了1.0s之后，会右移一小格，当前的单位时间段是1-6s，这个区域的请求已经超过限定的5了，已触发限流啦。

TIPS: 当滑动窗口的格子周期划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。

缺点：滑动窗口算法虽然解决了固定窗口的临界问题，但是一旦到达限流后，**请求都会直接暴力被拒绝**。酱紫我们会损失一部分请求，这其实对于产品来说，并不太友好。

### 漏桶算法 

漏桶算法比起窗口更柔顺,能很好避免暴力拒绝请求的情况,他是会有个桶当你发起请求的时候都会把请求放进桶里,然后桶会有个口来漏水,也就是说会有个口按固定速度来处理请求,这样就不会出现在短时间内请求塞满全部拒绝,而是由固定速度来处理请求,然后所有请求放进桶里,当超过桶阈值才丢弃,系统利用率不高

![img](https://cdn.nlark.com/yuque/0/2024/png/38443033/1718875284569-4a45607b-381e-4bb0-8786-c5994f2caa02.png?x-oss-process=image%2Fformat%2Cwebp%2Fresize%2Cw_937%2Climit_0)

### 令牌桶算法

**面对突发流量**的时候，我们可以使用令牌桶算法限流。

令牌桶算法原理：

●有一个令牌管理员，根据限流大小，定速往令牌桶里放令牌。

●如果令牌数量满了，超过令牌桶容量的限制，那就丢弃。

●系统在接受到一个用户请求时，都会先去令牌桶要一个令牌。如果拿到令牌，那么就处理这个请求的业务逻辑；

●如果拿不到令牌，就直接拒绝这个请求。

![img](https://cdn.nlark.com/yuque/0/2024/png/38443033/1718875293159-93583f21-1d1c-4667-803f-fd13829a123c.png?x-oss-process=image%2Fformat%2Cwebp%2Fresize%2Cw_937%2Climit_0)

如果令牌发放的策略正确，这个系统即不会被拖垮，也能提高机器的利用率。可以根据系统的性能调整令牌的发放

### 区别

它们的区别是，漏桶和令牌桶都可以处理突发流量，其中漏桶可以做到绝对的平滑，令牌桶有可能会产生突发大量请求的情况，一般nginx限流采用的漏桶，spring cloud gateway中可以支持令牌桶算法

# 什么是服务雪崩，怎么解决这个问题？

服务雪崩是指一个服务失败，导致整条链路的服务都失败的情形

一般我们在项目解决的话就是两种方案，第一个是服务降级，第二个是服务熔断，如果流量太大的话，可以考虑限流

- 服务降级：服务自我保护的一种方式，或者保护下游服务的一种方式，用于确保服务不会受请求突增影响变得不可用，确保服务不会崩溃，一般在实际开发中与feign接口整合，编写降级逻辑

- 服务熔断：默认关闭，需要手动打开，如果检测到 10 秒内请求的失败率超过 50%，就触发熔断机制。之后每隔 5 秒重新尝试请求微服务，如果微服务不能响应，继续走熔断机制。如果微服务可达，则关闭熔断机制，恢复正常请求

# 你们的微服务是怎么监控的？

我们项目中采用的skywalking进行监控的

1，skywalking主要可以监控接口、服务、物理实例的一些状态。特别是在压测的时候可以看到众多服务中哪些服务和接口比较慢，我们可以针对性的分析和优化。

2，我们还在skywalking设置了告警规则，特别是在项目上线以后，如果报错，我们分别设置了可以给相关负责人发短信和发邮件，第一时间知道项目的bug情况，第一时间修复